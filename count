import pickle
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import pandas as pd

# Example Data and Preprocessing
required_columns = ["column1", "column2", "column3"]
data = pd.DataFrame({
    "column1": [1, 2, 3],
    "column2": [4, 5, 6],
    "column3": [7, 8, 9]
})

# Preprocessing
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data[required_columns])

# Isolation Forest Model
iso_model = IsolationForest(n_estimators=100, random_state=42)
iso_model.fit(scaled_data)

# Combine all objects into a dictionary
objects_to_save = {
    "preprocessing": scaler,
    "model": iso_model,
    "required_columns": required_columns
}

# Save all objects to a single pickle file
with open("all_objects.pkl", "wb") as f:
    pickle.dump(objects_to_save, f)

print("All objects have been saved into one pickle file!")