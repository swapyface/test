import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.metrics import precision_recall_curve

# Load your dataset (assuming it's a Pandas DataFrame with features and ground truth labels)
# Replace 'df' with your actual dataset
X = df.drop(columns=['label'])  # Features
y_true = df['label']  # Ground truth (1 = outlier, 0 = normal)

# Train Isolation Forest without a fixed contamination level
iso_forest = IsolationForest(n_estimators=300, max_samples=0.6, max_features=0.8, random_state=42)
iso_forest.fit(X)

# Get anomaly scores (lower scores mean higher anomaly likelihood)
scores = iso_forest.decision_function(X)

# Compute Precision-Recall Curve
precision, recall, thresholds = precision_recall_curve(y_true, -scores)  # Invert scores for correct PR curve

# Define target recall (adjust as needed)
target_recall = 0.9  

# Find the best threshold that achieves at least the target recall
best_threshold = thresholds[np.argmax(recall >= target_recall)]

# Predict outliers using the selected threshold
y_pred = np.where(scores < best_threshold, 1, 0)  # 1 = outlier, 0 = normal

# Calculate final recall to confirm
final_recall = np.sum((y_pred == 1) & (y_true == 1)) / np.sum(y_true == 1)
print(f"Selected Threshold: {best_threshold}")
print(f"Final Recall: {final_recall}")