import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import r2_score

# Load dataset (replace with your actual dataset)
# df = pd.read_csv("your_data.csv")

# Example dataset (Replace this with your actual data)
np.random.seed(42)
df = pd.DataFrame({
    'feature1': np.random.rand(100),
    'feature2': np.random.rand(100),
    'feature3': np.random.rand(100),
    'target': np.random.rand(100) * 100
})

# Define features and target
X = df.drop(columns=['target'])  # Independent variables
y = df['target']  # Dependent variable

# Train-Test Split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

# Reshape y for scaling
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()

# Train SVR Model
svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)
svr.fit(X_train_scaled, y_train_scaled)

# Predictions
y_pred_scaled = svr.predict(X_test_scaled)

# Inverse Transform Predictions
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

# Evaluate Model
r2 = r2_score(y_test, y_pred)
n, p = X_test.shape  # Number of observations and predictors
adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

# Print Results
print(f"R² Score: {r2:.4f}")
print(f"Adjusted R² Score: {adjusted_r2:.4f}")