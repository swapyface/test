import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder
from scipy import stats

# Load the dataset
data = pd.read_csv('your_dataset.csv')

# One-hot encode categorical variables
categorical_cols = data.select_dtypes(include=['object']).columns
encoder = OneHotEncoder(drop='first', sparse=False)
encoded_cols = pd.DataFrame(encoder.fit_transform(data[categorical_cols]))
encoded_cols.columns = encoder.get_feature_names(categorical_cols)

# Drop the original categorical columns and concatenate encoded ones
data = data.drop(categorical_cols, axis=1)
data = pd.concat([data, encoded_cols], axis=1)

# Split the data into train and test sets
X = data.drop('target_column', axis=1)  # Replace with your dependent variable column name
y = data['target_column']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model (Random Forest Regressor)
model = RandomForestRegressor()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Calculate the IQR
Q1 = stats.scoreatpercentile(y_test, 25)
Q3 = stats.scoreatpercentile(y_test, 75)
IQR = Q3 - Q1

# Check if the prediction is within the IQR
def check_prediction_within_iqr(y_true, y_pred, Q1, Q3):
    result = []
    for pred in y_pred:
        if Q1 <= pred <= Q3:
            result.append("Good Value")
        else:
            result.append("Bad Value")
    return result

results = check_prediction_within_iqr(y_test, y_pred, Q1, Q3)

# Output the result
output = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Result': results})
print(output)