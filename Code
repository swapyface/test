import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder

class Preprocessor:
    def __init__(self, file_path, required_columns):
        self.file_path = file_path
        self.required_columns = required_columns

    def load_data(self):
        try:
            data = pd.read_csv(self.file_path)
            print(f"File '{self.file_path}' loaded successfully.")
            return data
        except FileNotFoundError:
            raise FileNotFoundError(f"File '{self.file_path}' not found.")
        except pd.errors.EmptyDataError:
            raise ValueError(f"File '{self.file_path}' is empty.")
        except Exception as e:
            raise Exception(f"An error occurred while loading the file: {e}")

    def validate_columns(self, data):
        missing_columns = [col for col in self.required_columns if col not in data.columns]
        if missing_columns:
            raise ValueError(f"Missing required columns: {missing_columns}")
        print("All required columns are present.")

    def handle_missing_values(self, data):
        for col in data.columns:
            if pd.api.types.is_numeric_dtype(data[col]):
                data[col].fillna(0, inplace=True)
            elif pd.api.types.is_object_dtype(data[col]):
                data[col].fillna("unknown", inplace=True)
            elif pd.api.types.is_datetime64_any_dtype(data[col]):
                data[col].fillna(pd.to_datetime("0000-00-00", errors='coerce'), inplace=True)
        return data

    def preprocess(self):
        # Load the dataset
        data = self.load_data()

        # Validate the required columns
        self.validate_columns(data)

        # Handle missing values
        data = self.handle_missing_values(data)

        # Standardize numerical columns (e.g., 'price')
        scaler = StandardScaler()
        if 'price' in data.columns:
            data['scaled_price'] = scaler.fit_transform(data[['price']])

        # One-hot encode categorical columns (e.g., 'rating')
        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
        if 'rating' in data.columns:
            rating_encoded = encoder.fit_transform(data[['rating']])
            rating_encoded_df = pd.DataFrame(rating_encoded, columns=encoder.get_feature_names_out(['rating']))
            data = pd.concat([data, rating_encoded_df], axis=1)

        # Flag records with WR, NR, or unknown ratings
        flagged_data = data[data['rating'].isin(['WR', 'NR', 'unknown'])]
        non_flagged_data = data[~data['rating'].isin(['WR', 'NR', 'unknown'])]

        return flagged_data, non_flagged_data
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import IsolationForest
from preprocessing import preprocess_data
import logging

class OutlierModel:
    def __init__(self):
        self.scaler = StandardScaler()
        self.encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

    def set_model_params(self, data_length):
        # Set model parameters based on the data length
        if data_length > 50000:
            return IsolationForest(n_estimators=200, max_samples=0.8, contamination=0.05, random_state=42)
        else:
            return IsolationForest(n_estimators=100, max_samples='auto', contamination=0.1, random_state=42)

    def fit_predict(self, df):
        try:
            # Standardizing the 'price' column
            df['scaled_price'] = self.scaler.fit_transform(df[['price']])
            
            # Encoding categorical columns
            cat_columns = df.select_dtypes(include=['object']).columns
            if len(cat_columns) > 0:
                encoded_data = self.encoder.fit_transform(df[cat_columns])
                df = pd.concat([df, pd.DataFrame(encoded_data)], axis=1)

            # Adjust model parameters dynamically
            model = self.set_model_params(len(df))
            df['outlier_score'] = model.fit_predict(df[['scaled_price']])
            df['outlier_label'] = df['outlier_score'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')

            return df
        except Exception as e:
            logging.error(f"Error in fit_predict: {e}")
            return pd.DataFrame()  # Return empty DataFrame in case of error

if __name__ == "__main__":
    try:
        # Load and preprocess data
        rating_categories = ['Low', 'Medium', 'High']  # Example categories
        for rating in rating_categories:
            df_flagged, df_non_flagged = preprocess_data(rating)
            if df_non_flagged.empty:
                logging.warning(f"No non-flagged data for rating: {rating}")
                continue

            # Model training and prediction
            model = OutlierModel()
            result_df = model.fit_predict(df_non_flagged)

            # Combine flagged and non-flagged data
            final_df = pd.concat([df_flagged, result_df])

            # Save the result
            final_df.to_csv(f"outlier_results_{rating}.csv", index=False)
    except Exception as e:
        logging.error(f"Error in main program: {e}")

